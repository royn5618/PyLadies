{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYD3omF/cMgi1/eY2vfckt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/royn5618/Talks_Resources/blob/main/PyLadies/TextDataScrape_ThreeQuickWays/Quick_Easy_PythonModules_TextData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wikipedia\n",
        "\n",
        "GitHub: https://github.com/goldsmith/Wikipedia\n",
        "\n",
        "Wikipedia is a Python library that makes it easy to access and parse data from Wikipedia."
      ],
      "metadata": {
        "id": "94rryRB9bNNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wikipedia"
      ],
      "metadata": {
        "id": "UPvvjOlobm9u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b5a3c4-f21b-4513-c494-ea6b2630fd62"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from wikipedia) (2.25.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (4.0.0)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11695 sha256=9b0279e4a9fa7b1e8b820226108aa9a5572004806ee23ff5ba06bfba169f0414\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/93/05/72c05349177dca2e0ba31a33ba4f7907606f7ddef303517c6a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wikipedia\n",
        "results_list = wikipedia.search(\"pyladies\") # Enter you search term\n",
        "results_list"
      ],
      "metadata": {
        "id": "fAJWnp2tbM8K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28c28ee-9b1e-467d-f400-c4d729683950"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PyLadies',\n",
              " 'Python Software Foundation',\n",
              " 'Python (programming language)',\n",
              " 'Python Conference',\n",
              " 'List of free and open-source software organizations',\n",
              " 'Timeline of women in computing',\n",
              " 'Dogpatch Labs']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = wikipedia.search(\"pyladies AND python\") # Enter you search term\n",
        "results_list"
      ],
      "metadata": {
        "id": "zwm1_DVxcf6m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ffd0f3-b614-4e8b-b8f7-97334e78d019"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PyLadies',\n",
              " 'Python Conference',\n",
              " 'Python Software Foundation',\n",
              " 'Python (programming language)',\n",
              " 'List of free and open-source software organizations',\n",
              " 'Timeline of women in computing']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = wikipedia.search(\"pyladies OR python\")\n",
        "results_list"
      ],
      "metadata": {
        "id": "qbvQlSHCcbIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e163e556-2757-430d-9fc0-dd71ef852902"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PyLadies',\n",
              " 'Python Conference',\n",
              " 'Python Software Foundation',\n",
              " 'Python (programming language)',\n",
              " 'List of free and open-source software organizations',\n",
              " 'Monty Python',\n",
              " 'Monty Python and the Holy Grail',\n",
              " 'John Cleese',\n",
              " 'Eric Idle',\n",
              " 'Michael Palin']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = wikipedia.search(\"python\")\n",
        "results_list"
      ],
      "metadata": {
        "id": "b-Zp_5Utdc8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_list = wikipedia.search(\"python AND pyladies\")\n",
        "results_list"
      ],
      "metadata": {
        "id": "yJgEgbFAdg7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b9d7d4-ac21-485e-9d61-2a009c5f2293"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PyLadies',\n",
              " 'Python Conference',\n",
              " 'Python Software Foundation',\n",
              " 'Python (programming language)',\n",
              " 'List of free and open-source software organizations',\n",
              " 'Timeline of women in computing']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_page_obj = wikipedia.page('PyLadies')\n",
        "wiki_page_obj"
      ],
      "metadata": {
        "id": "gLU-15xtuCb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd109141-8776-4744-8a3c-a6e42050aa39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<WikipediaPage 'PyLadies'>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_page_obj.content"
      ],
      "metadata": {
        "id": "tvBQfUUMuS7E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e30b64af-980f-4926-eca4-977008fbddee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PyLadies is an international mentorship group which focuses on helping more women become active participants in the Python open-source community. It is part of the Python Software Foundation. It was started in Los Angeles in 2011. The mission of the group is to create a diverse Python community through outreach, education, conferences and social gatherings. PyLadies also provides funding for women to attend open source conferences. The aim of PyLadies is increasing the participation of women in computing. PyLadies became a multi-chapter organization with the founding of the Washington, D.C., chapter in August 2011. The group currently has more than 40 chapters around the world.\\n\\n\\n== History ==\\nThe organization was created in Los Angeles in April 2011 by seven women: Audrey Roy Greenfeld, Christine Cheung, Esther Nam, Jessica Venticinque (Stanton at the time), Katharine Jarmul, Sandy Strong, and Sophia Viklund. Around 2012, the organization filed for nonprofit status.As of November 2022, PyLadies has over 100 chapters.\\n\\n\\n== About ==\\nPyLadies has conducted outreach events for both beginners and experienced users. PyLadies has conducted hackathons, social nights and workshops for Python enthusiasts.\\n\\nEach chapter is free to run themselves as they wish as long as they are focused on the goal of empowering women and other marginalized genders in tech. Women make up the majority of the group, but membership is not limited to women and the group is open to helping people who identify as other gender identities as well.\\n\\n\\n== References ==\\n\\n\\n== External links ==\\nPyLadies Website'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_page_obj.url"
      ],
      "metadata": {
        "id": "Dc5f3kpJuUgX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86b87cda-6a9c-4e0c-8826-d37e35055941"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://en.wikipedia.org/wiki/PyLadies'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_page_obj.links"
      ],
      "metadata": {
        "id": "I4wW6uO3uW_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80ad83b9-938a-4338-9e6b-fef589e696da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Gender identity',\n",
              " 'Los Angeles',\n",
              " 'Mentorship',\n",
              " 'Open-source community',\n",
              " 'Outreach',\n",
              " 'Python (programming language)',\n",
              " 'Python Software Foundation',\n",
              " 'Washington, D.C.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_search_results = []"
      ],
      "metadata": {
        "id": "CPQiolVebwoL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yMomvQcCYARW"
      },
      "outputs": [],
      "source": [
        "for each_result in results_list:\n",
        "    wiki_page_result = {}\n",
        "    wiki_page_obj = wikipedia.page(each_result)\n",
        "    wiki_page_result['title'] = wiki_page_obj.title\n",
        "    wiki_page_result['content'] = wiki_page_obj.content\n",
        "    wiki_page_result['url'] = wiki_page_obj.url\n",
        "    wiki_page_result['links'] = wiki_page_obj.links\n",
        "    wiki_search_results.append(wiki_page_result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pd.DataFrame(wiki_search_results)"
      ],
      "metadata": {
        "id": "3JfIxVTJua4p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "d1bf6742-5dc2-402a-bf5e-f3e04dbc6bc2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0                                           PyLadies   \n",
              "1                                  Python Conference   \n",
              "2                         Python Software Foundation   \n",
              "3                      Python (programming language)   \n",
              "4  List of free and open-source software organiza...   \n",
              "5                     Timeline of women in computing   \n",
              "\n",
              "                                             content  \\\n",
              "0  PyLadies is an international mentorship group ...   \n",
              "1  The Python Conference (also called PyCon: 564 ...   \n",
              "2  The Python Software Foundation (PSF) is an Ame...   \n",
              "3  Python is a high-level, general-purpose progra...   \n",
              "4  The following are notable organizations devote...   \n",
              "5  This is a timeline of women in computing. It c...   \n",
              "\n",
              "                                                 url  \\\n",
              "0             https://en.wikipedia.org/wiki/PyLadies   \n",
              "1    https://en.wikipedia.org/wiki/Python_Conference   \n",
              "2  https://en.wikipedia.org/wiki/Python_Software_...   \n",
              "3  https://en.wikipedia.org/wiki/Python_(programm...   \n",
              "4  https://en.wikipedia.org/wiki/List_of_free_and...   \n",
              "5  https://en.wikipedia.org/wiki/Timeline_of_wome...   \n",
              "\n",
              "                                               links  \n",
              "0  [Gender identity, Los Angeles, Mentorship, Ope...  \n",
              "1  [Atlanta, COVID-19 pandemic, Chicago, Code of ...  \n",
              "2  [501(c), Asynchronous Server Gateway Interface...  \n",
              "3  [\"Hello, World!\" program, 15.ai, 3ds Max, ?:, ...  \n",
              "4  [.NET Foundation, .NET Framework, Academic Fre...  \n",
              "5  [A-0 System, ACM Software System Award, ACM Tr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4cf2035a-8357-4a2e-b981-d5ad04fce0c0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>content</th>\n",
              "      <th>url</th>\n",
              "      <th>links</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>PyLadies</td>\n",
              "      <td>PyLadies is an international mentorship group ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/PyLadies</td>\n",
              "      <td>[Gender identity, Los Angeles, Mentorship, Ope...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Python Conference</td>\n",
              "      <td>The Python Conference (also called PyCon: 564 ...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Python_Conference</td>\n",
              "      <td>[Atlanta, COVID-19 pandemic, Chicago, Code of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Python Software Foundation</td>\n",
              "      <td>The Python Software Foundation (PSF) is an Ame...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Python_Software_...</td>\n",
              "      <td>[501(c), Asynchronous Server Gateway Interface...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Python (programming language)</td>\n",
              "      <td>Python is a high-level, general-purpose progra...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Python_(programm...</td>\n",
              "      <td>[\"Hello, World!\" program, 15.ai, 3ds Max, ?:, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>List of free and open-source software organiza...</td>\n",
              "      <td>The following are notable organizations devote...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/List_of_free_and...</td>\n",
              "      <td>[.NET Foundation, .NET Framework, Academic Fre...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Timeline of women in computing</td>\n",
              "      <td>This is a timeline of women in computing. It c...</td>\n",
              "      <td>https://en.wikipedia.org/wiki/Timeline_of_wome...</td>\n",
              "      <td>[A-0 System, ACM Software System Award, ACM Tr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4cf2035a-8357-4a2e-b981-d5ad04fce0c0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4cf2035a-8357-4a2e-b981-d5ad04fce0c0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4cf2035a-8357-4a2e-b981-d5ad04fce0c0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Python Wrapper for Twitter using SNScrape\n",
        "\n",
        "GitHub: https://github.com/JustAnotherArchivist/snscrape\n",
        "\n",
        "Tutorial: https://betterprogramming.pub/how-to-scrape-tweets-with-snscrape-90124ed006af"
      ],
      "metadata": {
        "id": "Y0Oifldvu0Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install snscrape"
      ],
      "metadata": {
        "id": "xGmQ4uMDuz0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "573369e7-90b1-4937-b943-df2a2595ad4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting snscrape\n",
            "  Downloading snscrape-0.5.0.20230113-py3-none-any.whl (69 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/69.2 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from snscrape) (3.9.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.8/dist-packages (from snscrape) (2.25.1)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from snscrape) (2022.7.1)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.5.0.20230113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import snscrape.modules.twitter as sntwitter"
      ],
      "metadata": {
        "id": "vH_mCYnGw56x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sntwitter.TwitterSearchScraper('from:PyLadiesDub').get_items()"
      ],
      "metadata": {
        "id": "o_RXDS5jxFVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9be7531-3212-4a20-ac84-598e15ac2123"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object TwitterSearchScraper.get_items at 0x7f6559c13a50>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in sntwitter.TwitterSearchScraper('from:PyLadiesDub').get_items():\n",
        "    print(\"Tweet Date: \", tweet.date)\n",
        "    print(\"Tweet ID: \", tweet.id)\n",
        "    print(\"Tweet Content: \", tweet.content)\n",
        "    print(\"Twitter User: \", tweet.user.username)\n",
        "    break"
      ],
      "metadata": {
        "id": "-pdTsrPWxvks",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e10870b6-4801-4318-eda4-32756aa8726a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Date:  2023-02-21 18:50:15+00:00\n",
            "Tweet ID:  1628104830920151040\n",
            "Tweet Content:  SNScrape scraping popular social media, in this demo, it's getting content from Twitter. #LiveDemo #Python #Data \n",
            "\n",
            "🔴 Live via https://t.co/Ik33aWigNh https://t.co/T1Q3e56S7f\n",
            "Twitter User:  PyLadiesDub\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-e0e7be56887f>:4: FutureWarning: content is deprecated, use rawContent instead\n",
            "  print(\"Tweet Content: \", tweet.content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in sntwitter.TwitterSearchScraper('#PyLadies #Hamburg').get_items():\n",
        "    print(\"Tweet Date: \", tweet.date)\n",
        "    print(\"Tweet ID: \", tweet.id)\n",
        "    print(\"Tweet Content: \", tweet.content)\n",
        "    print(\"Twitter User: \", tweet.user.username)\n",
        "    break"
      ],
      "metadata": {
        "id": "LbhOotM30BqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4649f91b-21a6-426e-c2ec-dc42a55a9f17"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tweet Date:  2020-06-29 07:00:39+00:00\n",
            "Tweet ID:  1277497189095411712\n",
            "Tweet Content:  Were you always curious about NLP but  didn’t get a chance to get started? Join us for an intro to NLP workshop with @ACosseron and Eva Jaumann \n",
            "\n",
            "#pyladies #pyladiesHH @pyladies #nlp #hamburg \n",
            "Intro to NLP or what is the meaning of \"Hello world\" https://t.co/PHEH2Bu91R\n",
            "Twitter User:  PyLadiesHH\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-01a31d58ab02>:4: FutureWarning: content is deprecated, use rawContent instead\n",
            "  print(\"Tweet Content: \", tweet.content)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attributes Available:\n",
        "\n",
        "1. URL\n",
        "2. Date\n",
        "3. content\n",
        "4. id\n",
        "5. user\n",
        "  - username\n",
        "  - display name\n",
        "  - id\n",
        "  - description\n",
        "  - verified\n",
        "  - followersCount\n",
        "  - friendsCount\n",
        "  - location\n",
        "6. replyCount\n",
        "7. retweetCount\n",
        "8. likeCount\n",
        "9. media\n",
        "10. mentionedUsers\n",
        "11. Lang\n",
        "\n",
        "  Find a wider list on the tutorial by the author"
      ],
      "metadata": {
        "id": "Z0GWMKJuGJp7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Usage of AND / OR for combinations of search terms\n",
        "\n",
        "for tweet in sntwitter.TwitterSearchScraper('#PyLadies OR #Hamburg').get_items():\n",
        "    print(\"Tweet Date: \", tweet.date)\n",
        "    print(\"Tweet ID: \", tweet.id)\n",
        "    print(\"Tweet Content: \", tweet.content)\n",
        "    print(\"Twitter User: \", tweet.user.username)\n",
        "    break"
      ],
      "metadata": {
        "id": "ZjhthJgG0DbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "''' Sample Code'''\n",
        "\n",
        "# Creating list to append tweet data to\n",
        "tweets_list1 = []\n",
        "maxTweets = 50\n",
        "# Using TwitterSearchScraper to scrape data \n",
        "for i,tweet in enumerate(sntwitter.TwitterSearchScraper('from:PyLadiesDub since:2023-01-01 until:2023-02-01').get_items()):\n",
        "    if i > maxTweets:\n",
        "        break\n",
        "    tweets_list1.append([tweet.date, tweet.id, tweet.rawContent, tweet.user.username])\n",
        "\n",
        "df = pd.DataFrame(tweets_list1, columns = ['date', 'id', 'content', 'username'])\n",
        "df.index = pd.to_datetime(df['date'])\n",
        "df.drop(columns='date', inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "nIBY5u9txOEW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "7b914575-a35d-4702-f0b8-f30a06647b35"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            id  \\\n",
              "date                                             \n",
              "2023-01-17 19:08:34+00:00  1615425865801732097   \n",
              "2023-01-17 19:02:40+00:00  1615424384172445696   \n",
              "2023-01-17 18:40:20+00:00  1615418762156511245   \n",
              "2023-01-17 16:31:11+00:00  1615386260650196999   \n",
              "2023-01-17 09:30:30+00:00  1615280392633712644   \n",
              "\n",
              "                                                                     content  \\\n",
              "date                                                                           \n",
              "2023-01-17 19:08:34+00:00  Uffa's starting her talk now on \"Update Nested...   \n",
              "2023-01-17 19:02:40+00:00  After \"Mitigating Bias in #AI\" by Arthur Lubam...   \n",
              "2023-01-17 18:40:20+00:00  Our first talk just kicked off with Arthur Lub...   \n",
              "2023-01-17 16:31:11+00:00  Counting down to our 1st #PyLadies Dublin meet...   \n",
              "2023-01-17 09:30:30+00:00  🔔 #PyLadies Dublin virtual event is on this ev...   \n",
              "\n",
              "                              username  \n",
              "date                                    \n",
              "2023-01-17 19:08:34+00:00  PyLadiesDub  \n",
              "2023-01-17 19:02:40+00:00  PyLadiesDub  \n",
              "2023-01-17 18:40:20+00:00  PyLadiesDub  \n",
              "2023-01-17 16:31:11+00:00  PyLadiesDub  \n",
              "2023-01-17 09:30:30+00:00  PyLadiesDub  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55ff1f55-572f-4454-b6ce-2f764ae58db7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>content</th>\n",
              "      <th>username</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-01-17 19:08:34+00:00</th>\n",
              "      <td>1615425865801732097</td>\n",
              "      <td>Uffa's starting her talk now on \"Update Nested...</td>\n",
              "      <td>PyLadiesDub</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17 19:02:40+00:00</th>\n",
              "      <td>1615424384172445696</td>\n",
              "      <td>After \"Mitigating Bias in #AI\" by Arthur Lubam...</td>\n",
              "      <td>PyLadiesDub</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17 18:40:20+00:00</th>\n",
              "      <td>1615418762156511245</td>\n",
              "      <td>Our first talk just kicked off with Arthur Lub...</td>\n",
              "      <td>PyLadiesDub</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17 16:31:11+00:00</th>\n",
              "      <td>1615386260650196999</td>\n",
              "      <td>Counting down to our 1st #PyLadies Dublin meet...</td>\n",
              "      <td>PyLadiesDub</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-01-17 09:30:30+00:00</th>\n",
              "      <td>1615280392633712644</td>\n",
              "      <td>🔔 #PyLadies Dublin virtual event is on this ev...</td>\n",
              "      <td>PyLadiesDub</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55ff1f55-572f-4454-b6ce-2f764ae58db7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55ff1f55-572f-4454-b6ce-2f764ae58db7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55ff1f55-572f-4454-b6ce-2f764ae58db7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Jha7iGHqzfQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3aab534-614a-4190-8d81-72995af85003"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "DatetimeIndex: 7 entries, 2023-01-17 19:08:34+00:00 to 2023-01-04 16:24:56+00:00\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7 non-null      int64 \n",
            " 1   content   7 non-null      object\n",
            " 2   username  7 non-null      object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 224.0+ bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pattern for Twitter and OOB Applied-NLP \n",
        "\n",
        "GitHub: https://github.com/clips/pattern"
      ],
      "metadata": {
        "id": "_pe1mNxdzmft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pattern"
      ],
      "metadata": {
        "id": "kncCNZORy6Fz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a4fcd8-4ed0-4f4b-a088-ab924adbd790"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pattern\n",
            "  Downloading Pattern-3.6.0.tar.gz (22.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.2/22.2 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.8/dist-packages (from pattern) (0.16.0)\n",
            "Collecting backports.csv\n",
            "  Downloading backports.csv-1.0.7-py2.py3-none-any.whl (12 kB)\n",
            "Collecting mysqlclient\n",
            "  Downloading mysqlclient-2.1.1.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.1/88.1 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (from pattern) (4.6.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.8/dist-packages (from pattern) (4.9.2)\n",
            "Collecting feedparser\n",
            "  Downloading feedparser-6.0.10-py3-none-any.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.1/81.1 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six\n",
            "  Downloading pdfminer.six-20221105-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pattern) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pattern) (1.7.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (from pattern) (3.7)\n",
            "Collecting python-docx\n",
            "  Downloading python-docx-0.8.11.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cherrypy\n",
            "  Downloading CherryPy-18.8.0-py2.py3-none-any.whl (348 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.4/348.4 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pattern) (2.25.1)\n",
            "Collecting cheroot>=8.2.1\n",
            "  Downloading cheroot-9.0.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.6/100.6 KB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.8/dist-packages (from cherrypy->pattern) (9.0.0)\n",
            "Collecting portend>=2.1.1\n",
            "  Downloading portend-3.1.0-py3-none-any.whl (5.3 kB)\n",
            "Collecting jaraco.collections\n",
            "  Downloading jaraco.collections-3.8.0-py3-none-any.whl (10 kB)\n",
            "Collecting zc.lockfile\n",
            "  Downloading zc.lockfile-2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Collecting sgmllib3k\n",
            "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (2022.6.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk->pattern) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from pdfminer.six->pattern) (3.0.1)\n",
            "Collecting cryptography>=36.0.0\n",
            "  Downloading cryptography-39.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pattern) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.15.0)\n",
            "Collecting jaraco.functools\n",
            "  Downloading jaraco.functools-3.6.0-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.8/dist-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
            "Collecting tempora>=1.8\n",
            "  Downloading tempora-5.2.1-py3-none-any.whl (13 kB)\n",
            "Collecting jaraco.classes\n",
            "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
            "Collecting jaraco.text\n",
            "  Downloading jaraco.text-3.11.1-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from zc.lockfile->cherrypy->pattern) (57.4.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.8/dist-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.7.1)\n",
            "Collecting autocommand\n",
            "  Downloading autocommand-2.2.2-py3-none-any.whl (19 kB)\n",
            "Collecting jaraco.context>=4.1\n",
            "  Downloading jaraco.context-4.3.0-py3-none-any.whl (5.3 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (5.10.2)\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.8/dist-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.1.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.8/dist-packages (from importlib-resources->jaraco.text->jaraco.collections->cherrypy->pattern) (3.13.0)\n",
            "Building wheels for collected packages: pattern, mysqlclient, python-docx, sgmllib3k\n",
            "  Building wheel for pattern (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pattern: filename=Pattern-3.6-py3-none-any.whl size=22332722 sha256=9f57f8782f8ecc2fb541baf80a0b9ebd2e6bf8188e366eac98070ef0403353fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/ce/8f/bccc2d04f3a25a5a1dd19165b2855ad3203975f25edd5838d6\n",
            "  Building wheel for mysqlclient (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysqlclient: filename=mysqlclient-2.1.1-cp38-cp38-linux_x86_64.whl size=109201 sha256=7762290fe53c86a0fd9f71968453bd0ae2d0110824bdfaf723f1daa87c986ede\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/e1/84/a6185eaec318899f59a32d393af7729a0719cd93695d71f9a1\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-docx: filename=python_docx-0.8.11-py3-none-any.whl size=184505 sha256=e9deac4047f722738526296fa978b9edfb97db4a22c83acf76ca13d2e6dba4c5\n",
            "  Stored in directory: /root/.cache/pip/wheels/32/b8/b2/c4c2b95765e615fe139b0b17b5ea7c0e1b6519b0a9ec8fb34d\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6066 sha256=7fc5e5a6779004a712f010404de6ff0c2f703027647b1fd7b8c9dadf9ec67d75\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/63/2f/117884c3b19d46b64d3d61690333aa80c88dc14050e269c546\n",
            "Successfully built pattern mysqlclient python-docx sgmllib3k\n",
            "Installing collected packages: sgmllib3k, backports.csv, zc.lockfile, python-docx, mysqlclient, jaraco.functools, jaraco.context, jaraco.classes, feedparser, autocommand, tempora, jaraco.text, cryptography, cheroot, portend, pdfminer.six, jaraco.collections, cherrypy, pattern\n",
            "Successfully installed autocommand-2.2.2 backports.csv-1.0.7 cheroot-9.0.0 cherrypy-18.8.0 cryptography-39.0.1 feedparser-6.0.10 jaraco.classes-3.2.3 jaraco.collections-3.8.0 jaraco.context-4.3.0 jaraco.functools-3.6.0 jaraco.text-3.11.1 mysqlclient-2.1.1 pattern-3.6 pdfminer.six-20221105 portend-3.1.0 python-docx-0.8.11 sgmllib3k-1.0.0 tempora-5.2.1 zc.lockfile-2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pattern.web import Twitter"
      ],
      "metadata": {
        "id": "t3z7P6Eh6tpj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter = Twitter()"
      ],
      "metadata": {
        "id": "D4T6HlSg6zuw"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter.search('#pyladies', start=1, count=3)"
      ],
      "metadata": {
        "id": "FH4e3ZK463i7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a58309-49c2-4ec2-c4bb-725096f371ef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Result({'url': 'https://twitter.com/whykay/status/1628103458673786896', 'id': '1628103458673786896', 'text': \"RT @PyLadiesDub: Nabanita now up speaking at this evening's #PyLadies Dublin. #Python #Data\\n\\n🔴 Live via  https://t.co/Ik33aWigNh https://t.co/RanlgfVyeT\", 'language': 'en', 'author': 'whykay', 'date': 'Tue Feb 21 18:44:47 +0000 2023', 'shares': 1, 'profile': 'http://pbs.twimg.com/profile_images/1334538352993968128/HD6EYYqv_normal.jpg'}),\n",
              " Result({'url': 'https://twitter.com/PyLadiesDub/status/1628102339499368448', 'id': '1628102339499368448', 'text': \"Nabanita now up speaking at this evening's #PyLadies Dublin. #Python #Data\\n\\n🔴 Live via  https://t.co/Ik33aWigNh https://t.co/RanlgfVyeT\", 'language': 'en', 'author': 'PyLadiesDub', 'date': 'Tue Feb 21 18:40:21 +0000 2023', 'shares': 1, 'profile': 'http://pbs.twimg.com/profile_images/1509101369722122243/JeY-6p22_normal.jpg'}),\n",
              " Result({'url': 'https://twitter.com/BrianLinuxing/status/1628099981054705669', 'id': '1628099981054705669', 'text': 'RT @PyLadiesDub: Good evening, our #PyLadies Dublin event is about to start!\\nAnnouncements by @whykay first followed by Nabanita and then @micktwomey.\\n\\nℹ️ https://t.co/XcGyOvY5Tb\\n🔴 https://t.co/Ik33aWigNh', 'language': 'en', 'author': 'BrianLinuxing', 'date': 'Tue Feb 21 18:30:58 +0000 2023', 'shares': 1, 'profile': 'http://pbs.twimg.com/profile_images/1497165720525942794/OyFMQf0C_normal.jpg'})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attributes Available:\n",
        "1. URL\n",
        "2. ID - Twitter has unique ids for each so you can link back to SnScraper Tweet ID as well\n",
        "3. Text - Also called content in SnScaper\n",
        "4. Language\n",
        "5. Author\n",
        "6. Date\n",
        "7. Profile\n"
      ],
      "metadata": {
        "id": "2ZAJc_9T7ECp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "from pattern.en import tag\n",
        "from pattern.vector import KNN, count"
      ],
      "metadata": {
        "id": "5vx5KUEJuvE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278bc127-f6a7-4c90-adbb-1ccff9ad8d06"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Depending on the date being scraped at this moment this classifier can malfunction'''\n",
        "\n",
        "knn = KNN()\n",
        "for tweet in twitter.search('#pyladies', start=1, count=50):\n",
        "  s = tweet.text.lower()\n",
        "  # print(s)\n",
        "  # print(\"---\")\n",
        "  p = 'dublin' in s and 'YES' or 'NO'\n",
        "  v = tag(s)\n",
        "  # for word,pos in v:\n",
        "  #   print(\"Word:\", word)\n",
        "  #   print(\"POS:\", pos)\n",
        "  #   # break\n",
        "  # print(\"---\")\n",
        "  v = [word for word, pos in v if pos == 'IN' or pos == 'JJ']\n",
        "  # print(v)\n",
        "  v = count(v)\n",
        "  print(\"---\")\n",
        "  print(v)\n",
        "  if v:\n",
        "    knn.train(v, type=p)"
      ],
      "metadata": {
        "id": "IZpHN-P674lU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bac3bec9-4b5f-4746-c70c-045959c77fcd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{'dublin': 1, '@whykay': 1, 'nabanita': 1}\n",
            "---\n",
            "{'dublin': 1, '@whykay': 1, 'nabanita': 1}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{'dublin': 1, 'virtual': 1, 'nabanita': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'virtual': 1, 'nabanita': 1}\n",
            "---\n",
            "{'dublin': 1, 'virtual': 1, 'nabanita': 1}\n",
            "---\n",
            "{'dublin': 1, 'virtual': 1, 'nabanita': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'dublin': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1, '🔴': 1}\n",
            "---\n",
            "{'screenshot': 1, 'curious': 1, 'active': 1, 'fantastic': 1}\n",
            "---\n",
            "{'screenshot': 1, 'curious': 1, 'active': 1, 'fantastic': 1}\n",
            "---\n",
            "{'excited': 1, '🤓': 1}\n",
            "---\n",
            "{'@uliana_munich': 1, 'awesome': 1, 'munich': 1}\n",
            "---\n",
            "{'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'excited': 1, '🤓': 1}\n",
            "---\n",
            "{'excited': 1, '🤓': 1}\n",
            "---\n",
            "{'excited': 1, '🤓': 1}\n",
            "---\n",
            "{'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'https://t.co/jpsbw5i7oe': 1}\n",
            "---\n",
            "{'happy': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'happy': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'happy': 1, 'quick': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'quick': 1, 'easy': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{}\n",
            "---\n",
            "{'quick': 1, 'easy': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{'quick': 1, 'easy': 1, 'no-scraper': 1, 'nabanita': 1}\n",
            "---\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn.classify('sweet little burger'))\n",
        "print(knn.classify('I am at pyladies dublin'))"
      ],
      "metadata": {
        "id": "HL5NGy5NDjd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbdb719-e3f4-4652-932b-22eabc3d03e7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO\n",
            "YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn.classify('It is a lovely day in dublin'))"
      ],
      "metadata": {
        "id": "NdSYOBtZD9sU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a494c9-be64-4945-dbf5-f4711a57f535"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn.classify('It is a lovely day in Munich'))"
      ],
      "metadata": {
        "id": "DBwyh6WWD8lx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9b085b3-05a5-43fa-92e0-29042d5edb3a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(knn.classify('It is a great day in Munich #dublin #munich #chicago'))"
      ],
      "metadata": {
        "id": "IAe91ni17zPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cca4c9d-9f22-4fae-83a6-edc38232f3de"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YES\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2Q_qBIRbubrf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}